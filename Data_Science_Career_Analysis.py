# -*- coding: utf-8 -*-
"""SIT742Task1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WKsZiOd6D_xxIbLR6oPhIMLI1JqqrrLw
"""

!pip install wget

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from pandas import datetime
import wget
import seaborn as sns
sns.set(style="whitegrid")

link_to_data = 'https://github.com/tulip-lab/sit742/raw/master/Assessment/2020/data/MCQResponses.csv'
DataSet = wget.download(link_to_data)

link_to_data = 'https://github.com/tulip-lab/sit742/raw/master/Assessment/2020/data/ConversionRates.csv'
DataSet = wget.download(link_to_data)

link_to_data = 'https://github.com/tulip-lab/sit742/raw/master/Assessment/2020/data/JobPostings.csv'
DataSet = wget.download(link_to_data)

df_demog =  pd.read_csv("MCQResponses.csv")
df_demog.head()

# Top five rows printed by using .head()

df_demog.isna().any()

# False = Has no NAN values True = Has

print(df_demog.isna().sum())
print(df_demog.notna().sum())

# The first output shows how many NaN values each column has; the second output shows how many normal values each column has

df_demog_ds =df_demog[df_demog.CurrentJobTitleSelect == 'Data Scientist']
len(df_demog_ds)

# The length shows there are 1263 rows; which means there are 1263 Data Scientists in this data frame

sns.set()
plt.pie(df_demog_ds.FormalEducation.value_counts(), labels=df_demog_ds.FormalEducation.unique(), 
        autopct=lambda p : '{:.2f}%  ({:,.0f})'.format(p,p 
        * sum(df_demog_ds.FormalEducation.value_counts())/100), radius=3, explode=[0,0,0,0.1,0.4,0.6],)
        
plt.show()

# Source: https://stackoverflow.com/questions/6170246/how-do-i-use-matplotlib-autopct

# This piechart shows what education data scientists' in this data frame. I sourced code from stackoverflow.com

df_conv =  pd.read_csv("ConversionRates.csv")

df_merge=pd.merge(df_demog_ds,df_conv,left_on="CompensationCurrency",right_on="originCountry", how="left")

df_merge['USDSalary']=df_merge["CompensationAmount"]*df_merge["exchangeRate"]

df_merge['AUDSalary']=df_merge['USDSalary']*100 /80.231

# I merged the data science frame and conversation frame together; then I created two new columns
# I converted all salaries to USD then I converted them to AUD using a currency exchange formula

x= df_merge.AUDSalary.median()
y = max(df_merge.AUDSalary)
print("AUD Salary Median: {}".format(x)) 
print("AUD Salary Max: {}".format(y)) 

# AUD salary median and max

plt.title("Boxplot of salary on Australia")

df_aud= df_merge[df_merge.Country == 'Australia']
ax = sns.boxplot(x=df_aud["AUDSalary"]) 
plt.xlabel('AUD Salary')

# I created a new dataframe from the merged dataframe with just Australian respondents

x= df_aud.AUDSalary.median()
y = max(df_aud.AUDSalary)
print("Australian Respondent AUD Salary Median: {}".format(x)) 
print("Australian Respondent AUD Salary Max: {}".format(y)) 

# Median and maxium salary of Australian respondents in AUD

df_aud_filter = df_aud[~(df_aud['AUDSalary'] > 250000)]

df_aud_filter = df_aud_filter[~(df_aud_filter['AUDSalary'] < 40000)]

x= df_aud_filter.AUDSalary.median()
y = max(df_aud_filter.AUDSalary)

print("Australian Respondent AUD Salary Median: {}".format(x)) 
print("Australian Respondent AUD Salary Max: {}".format(y)) 

# Source: https://stackoverflow.com/questions/52765186/boxplot-on-matplotlib-with-rows-according-if-column-x-has-a-certain-value
# I created a new dataframe with just the Australian respondents who earned an AUD salary between 40,000 and 250,000

plt.title("Boxplot of filtered salary on Australia")

ax = sns.boxplot(x=df_aud_filter["AUDSalary"]) 
plt.xlabel('AUD Salary Filtered')

# Boxplot of the filtered AUD Salary of Australian respondents.

plt.title("Boxplot of Age")

ax = sns.boxplot(x=df_demog_ds["Age"])

# Boxplot of Age

df_demog_ds.Age.describe().round(0)

# .describe() outputs the mean age

df_demog_ds.Age.median()

# .median() outputs the median age

# How many data scientsits aged between 24 and 60

len(df_demog_ds[(df_demog_ds.Age >24) & (df_demog_ds.Age < 60)])

# The length of the age column filtered for people who are aged between 24 and 60 shows the number

len(df_demog_ds[df_demog_ds['Age'] < 18])

# The length of the age column for everyone with the age between 18 and 0

plt.title("Boxplot of Gender")


df_demog_ds['GenderSelect'].value_counts().plot(kind='bar')

# A barchart of the distribution of gender of the dataframe; .value_counts() counts the number of different values

plt.title("Boxplot of Age with GenderSelect")


sns.boxplot(x=df_demog_ds["Age"], y=df_demog_ds["GenderSelect"])

# A simple boxplot of age and gender; gender on the y axis and age on the x axis

plt.figure(figsize=(12,8))
plt.title('Distribution of Gender')
plt.xlabel('Gender Select')
plt.ylabel('Percentage [%]')


sns.barplot(x="GenderSelect",y="Age",data=df_demog_ds, estimator=lambda x: len(x) / len(df_demog_ds) *100)
plt.ylabel('Percentage [%]')
plt.show()

# Source code: https://stackoverflow.com/questions/6170246/how-do-i-use-matplotlib-autopct
# This barchart shows the disribution of gender by percentage

#  creates and fills value into df_country

top5 = df_demog_ds['Country'].value_counts().index[:5]
df_country = df_demog_ds[df_demog_ds['Country'].isin(top5)]

df_country['Country'].value_counts()

# https://cmdlinetips.com/2019/03/how-to-select-top-n-rows-with-the-largest-values-in-a-columns-in-pandas/
# I created a new data frame called top 5 using .value_counts() I created another df based on it.

# Shows the Boxplot of country
plt.title("Boxplot of Top 5 Countries")

ax = sns.boxplot(x=df_country["Country"], y= np.arange(len(df_country)))

# Boxplot of the top 5 countries

#percentage
plt.figure(figsize=(12,8))
plt.title('Distribution of Top 5 country with data scientist count')
plt.xlabel('Country')
plt.ylabel('Percentage [%]')


# create and fill values into df_country_top5
df_country_top5 = df_demog_ds['Country'].value_counts().index[:5]
df_country = df_demog_ds[df_demog_ds['Country'].isin(top5)]


sns.barplot(x="Country",y= "Age",data=df_country, estimator=lambda x: len(x) / len(df_country) *100)
plt.ylabel('Percentage [%]')
plt.show()

#https://stackoverflow.com/questions/6170246/how-do-i-use-matplotlib-autopct
# I used the same dataframe I had previously created. I used a barchart to show the percntage distrbution.

countries = ["United States", "India", "Australia", "Pakistan"]

df_4= df_demog_ds[df_demog_ds.Country.isin(countries)] 

x= df_4.groupby(['Country','GenderSelect']).Age.mean().round(0)
y= df_4.groupby(['Country','GenderSelect']).Age.median()
print(x)
print(y)

#https://stackoverflow.com/questions/19960077/how-to-filter-pandas-dataframe-using-in-and-not-in-like-in-sql
# I made a new df with the four countries than I grouped the rows by country and gender; the first set is Age mean

import re
import nltk
from nltk.tokenize import RegexpTokenizer
from nltk.probability import *
from itertools import chain
#from tqdm import tqdm
import codecs
from nltk.corpus import stopwords 
nltk.download('stopwords')

df_text = pd.read_csv('JobPostings.csv')

lower = []
for item in df_text['job_description']:
    lower.append(item.lower())           # lowercase description

tokens = []


tokenizer = RegexpTokenizer("[\w']+")
for x in df_text['job_description'] :   
    print(tokenizer.tokenize(x))
    tokens.append(tokenizer.tokenize(x))
#https://towardsdatascience.com/an-introduction-to-tweettokenizer-for-processing-tweets-9879389f8fe7
# I used a for loop to tokenize the text and append it to tokens

stop_words = set(stopwords.words('english')) 

freq6000 = []




newtokens = []

for words in tokens:
    newtokens += words
FreqDist(newtokens)



fd_1 = FreqDist(newtokens)

freq6000 = list(filter(lambda x: x[1]>=6000, fd_1.items()))
# Source: https://stackoverflow.com/questions/38666973/pandas-nltk-tokenizing-unhashable-type-list
# I had to use a for loop to change the data type to use FreqDist on it; I then used a filter to select the correct words

freq6000

from collections import Counter
Counter(freq6000).most_common(10)

#https://stackoverflow.com/questions/28128125/sort-a-list-and-get-the-most-frequent-words
# Counter.most_common was used to display the top 10 highest fequency words from freq600

import nltk

nltk.download('punkt')

nltk.download('averaged_perceptron_tagger')

nltk.download('tagsets')

tagged_sent = nltk.tag.pos_tag(newtokens)

verbs = [w for w,t in tagged_sent if t.startswith('VB')]
nouns = [w for w,t in tagged_sent if t.startswith('NN')]

common_verbs = Counter(verbs).most_common(10)
common_nouns = Counter(nouns).most_common(10)

print("Top 10 Common Verbs = {}".format(common_verbs)) 
print("Top 10 Common Nouns = {}".format(common_nouns)) 

# https://github.com/tulip-lab/sit742/blob/fd8d5c44187875ba83f2dbf372d0c92a5d69e231/Jupyter/SIT742P04B-TextFeatures.ipynb
# I used an example from the tutorials to extract the top 10 highest frequency verbs and nouns
# This cell takes a long time to run